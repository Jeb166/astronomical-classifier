#!/usr/bin/env python
# -*- coding: utf-8 -*-

import streamlit as st

# UI baÅŸlÄ±ÄŸÄ± ve aÃ§Ä±klamasÄ± - En baÅŸta olmalÄ±
st.set_page_config(
    page_title="Astronomik SÄ±nÄ±flandÄ±rÄ±cÄ±",
    page_icon="ğŸ”­",
    layout="wide",
    initial_sidebar_state="expanded",
)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px
import seaborn as sns
import base64
from PIL import Image
from io import BytesIO
import streamlit.components.v1 as components
import urllib.parse as ul
import requests
import os
import time
from prediction import get_sdss_object_by_objid

# Add styling after page config
page_bg_img = '''
<style>
body {
    background-image: url("https://www.example.com/background.jpg");
    background-size: cover;
    background-attachment: fixed;
    color: #ffffff;
}
.sidebar .sidebar-content {
    background: rgba(0, 0, 0, 0.7);
    color: #ffffff;
}
</style>
'''
st.markdown(page_bg_img, unsafe_allow_html=True)

# Model iÅŸlevlerini ve tahmin iÅŸlevlerini iÃ§e aktar
from prediction import (
    load_models, predict, get_sdss_image, get_sdss_object_by_coords,
    make_feature_vector, plot_predictions, display_confidence_gauge, 
    get_object_info_text, get_spectra_link
)

# ---------------------------------------------------------------------
# Veri Ã¶n iÅŸleme fonksiyonu (test_rf.py'den adapte edildi)
# ---------------------------------------------------------------------
def preprocess_data(df, scaler, debug=False):
    """CSV verilerini RF modeli iÃ§in Ã¶n iÅŸler ve scaler ile uyumlu hale getirir"""
    try:
        if debug:
            st.write(f"Ã–n iÅŸleme Ã¶ncesi veri boyutu: {df.shape}")
        
        # EÄŸer verinin kopyasÄ±nÄ± oluÅŸturmamÄ±ÅŸsak, oluÅŸtur
        df = df.copy()
        
        # Koordinat ve ID sÃ¼tunlarÄ±nÄ± kaldÄ±r
        cols_to_drop = []
        for col in ['objid', 'specobjid', 'run', 'rerun', 'camcol', 'field', 'ra', 'dec']:
            if col in df.columns:
                cols_to_drop.append(col)
        
        if cols_to_drop:
            df = df.drop(cols_to_drop, axis=1)
            if debug:
                st.write(f"KaldÄ±rÄ±lan sÃ¼tunlar: {cols_to_drop}")
        
        # Kategorik sÃ¼tunlarÄ± ayÄ±r
        y = None
        if 'class' in df.columns:
            y = df['class'].copy()
            df = df.drop(['class'], axis=1)
        
        # Renk indekslerini ekle (eÄŸer beÅŸ temel filtre varsa)
        if all(band in df.columns for band in ['u', 'g', 'r', 'i', 'z']):
            if 'u_g' not in df.columns:
                df["u_g"] = df["u"] - df["g"]
            if 'g_r' not in df.columns:
                df["g_r"] = df["g"] - df["r"]
            if 'r_i' not in df.columns:
                df["r_i"] = df["r"] - df["i"]
            if 'i_z' not in df.columns:
                df["i_z"] = df["i"] - df["z"]
        
        # SayÄ±sal olmayan veya eksik deÄŸerleri kontrol et ve temizle
        non_numeric_cols = df.select_dtypes(exclude=['number']).columns
        if len(non_numeric_cols) > 0:
            if debug:
                st.warning(f"SayÄ±sal olmayan sÃ¼tunlar kaldÄ±rÄ±lÄ±yor: {non_numeric_cols}")
            df = df.drop(columns=non_numeric_cols)
        
        # NaN ve sonsuz deÄŸerleri kontrol et
        nan_count = df.isna().sum().sum()
        inf_count = ((df == np.inf) | (df == -np.inf)).sum().sum()
        if nan_count > 0 or inf_count > 0:
            if debug:
                st.warning(f"Eksik deÄŸerler bulundu: {nan_count} NaN, {inf_count} sonsuz deÄŸer")
            df.replace([np.inf, -np.inf], np.nan, inplace=True)
            df.fillna(df.median(), inplace=True)
        
        # Scaler'Ä±n Ã¶zellik adlarÄ±nÄ± al
        if hasattr(scaler, 'feature_names_in_'):
            scaler_columns = set(scaler.feature_names_in_)
            
            # Ã–zellik sÃ¼tunlarÄ±nÄ± scaler'da olan sÃ¼tunlarla eÅŸleÅŸtir
            feature_columns = set(df.columns)
            
            # Eksik sÃ¼tunlarÄ± kontrol et
            missing_columns = scaler_columns - feature_columns
            if missing_columns:
                if debug:
                    st.warning(f"Modelin beklediÄŸi bazÄ± sÃ¼tunlar eksik: {missing_columns}")
                # Eksik sÃ¼tunlar iÃ§in 0 ile doldur
                for col in missing_columns:
                    df[col] = 0
            
            # Fazla sÃ¼tunlarÄ± kontrol et
            extra_columns = feature_columns - scaler_columns
            if extra_columns:
                if debug:
                    st.warning(f"Modelde olmayan fazla sÃ¼tunlar kaldÄ±rÄ±lÄ±yor: {extra_columns}")
                df = df.drop(columns=extra_columns)
            
            # SÃ¼tun sÄ±ralamasÄ±nÄ± scaler ile uyumlu hale getir
            df = df[scaler.feature_names_in_]
        else:
            if debug:
                st.warning("Scaler'da feature_names_in_ Ã¶zelliÄŸi bulunamadÄ±. SÃ¼tun uyumluluÄŸu kontrol edilemiyor.")
        
        # Veriyi Ã¶lÃ§eklendir
        X = scaler.transform(df)
        
        if debug:
            st.write(f"Ã–n iÅŸleme sonrasÄ± Ã¶zellik vektÃ¶rÃ¼ boyutu: {X.shape}")
        
        return X, y
        
    except Exception as e:
        st.error(f"Veri Ã¶n iÅŸleme sÄ±rasÄ±nda hata: {str(e)}")
        return None, None

# En yakÄ±n SDSS objesini bulmak iÃ§in yardÄ±mcÄ± fonksiyon
def query_nearest_obj(ra, dec, radius=0.01):
    """
    Verilen koordinatlara yakÄ±n gÃ¶k cisimlerini araÅŸtÄ±rÄ±r.
    
    Parameters:
        ra (float): SaÄŸ aÃ§Ä±klÄ±k (derece)
        dec (float): Dik aÃ§Ä±klÄ±k (derece)
        radius (float): Arama yarÄ±Ã§apÄ± (derece); 0.01Â° â‰ˆ 36 aÃ§Ä± saniyesi
        
    Returns:
        pandas.DataFrame: Bulunan gÃ¶k cisimlerinin verileri
    """    # FarklÄ± SDSS DR API URL'lerini deneyelim - HTTP 500 hatasÄ± durumunda alternatif API'ler kullanÄ±lacak
    urls = [
        # DR18 en son sÃ¼rÃ¼m (navigasyon sayfasÄ±ndan)
        f"https://skyserver.sdss.org/dr18/SkyServer/SearchTools/RadialSearch?ra={ra}&dec={dec}&radius={radius}&format=json",
        
        # DR17 ve DR16 yedek sÃ¼rÃ¼mler
        f"https://skyserver.sdss.org/dr17/SkyServer/SearchTools/RadialSearch?ra={ra}&dec={dec}&radius={radius}&format=json",
        f"https://skyserver.sdss.org/dr16/SkyServer/SearchTools/RadialSearch?ra={ra}&dec={dec}&radius={radius}&format=json",
        
        # Web servisi API'leri
        f"http://skyserver.sdss.org/dr16/SkyServerWS/SearchTools/RadialSearch?ra={ra}&dec={dec}&radius={radius}&format=json",
        f"http://skyserver.sdss.org/dr17/SkyServerWS/SearchTools/RadialSearch?ra={ra}&dec={dec}&radius={radius}&format=json",
        f"http://skyserver.sdss.org/dr18/SkyServerWS/SearchTools/RadialSearch?ra={ra}&dec={dec}&radius={radius}&format=json",
        
        # Alternatif API uÃ§noktalarÄ±
        f"https://skyserver.sdss.org/dr16/SkyServer/Search/RadialSearch?format=json&ra={ra}&dec={dec}&radius={radius}",
        f"https://skyserver.sdss.org/dr17/SkyServer/Search/RadialSearch?format=json&ra={ra}&dec={dec}&radius={radius}",
        f"https://skyserver.sdss.org/dr18/SkyServer/Search/RadialSearch?format=json&ra={ra}&dec={dec}&radius={radius}",
        
        # CasJobs SQL sorgularÄ±
        f"http://skyserver.sdss.org/CasJobs/RestApi/contexts/default/query?query=SELECT+TOP+10+*+FROM+PhotoObj+WHERE+CONTAINS(POINT('J2000',ra,dec),CIRCLE('J2000',{ra},{dec},{radius}))+ORDER+BY+distance&format=json"
    ]    # User-Agent ekleyerek istek baÅŸlÄ±klarÄ±nÄ± hazÄ±rla
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept': 'application/json, text/javascript, */*',
        'Origin': 'https://skyserver.sdss.org',
        'Referer': 'https://skyserver.sdss.org/navigate/'
    }
    
    last_error = None
    
    # TÃ¼m API URL'lerini sÄ±rayla deneyelim
    for url in urls:
        # Debug iÃ§in URL'yi yazdÄ±r
        print(f"SDSS API URL deneniyor: {url}")
        
        try:
            # Daha uzun bir timeout sÃ¼resi ile isteÄŸi gÃ¶nder
            response = requests.get(url, headers=headers, timeout=60)
            
            if response.status_code == 200:
                # YanÄ±tÄ± gÃ¶ster ve debug
                content_type = response.headers.get('content-type', '')
                print(f"API yanÄ±t content-type: {content_type}")
                
                try:
                    js = response.json()
                    
                    # YanÄ±t yapÄ±sÄ±nÄ± debug iÃ§in yazdÄ±r
                    print(f"API yanÄ±t yapÄ±sÄ±: {type(js)}")
                    if isinstance(js, dict):
                        print(f"API yanÄ±t anahtarlarÄ±: {js.keys()}")
                    
                    # API yanÄ±tÄ± baÅŸarÄ±lÄ± ancak veri boÅŸ olabilir
                    if js is None or (isinstance(js, list) and len(js) == 0) or (isinstance(js, dict) and len(js) == 0):
                        print(f"Bu URL iÃ§in veri bulunamadÄ±: {url}")
                        continue
                    
                    # API yanÄ±t formatÄ±nÄ± kontrol et
                    if isinstance(js, dict) and "error" in js:
                        print(f"SDSS API hatasÄ±: {js['error']}")
                        continue
                    
                    # YanÄ±tta 'Exception' anahtarÄ± olmasÄ± durumu
                    if isinstance(js, dict) and "Exception" in js:
                        print(f"SDSS API Exception: {js['Exception']}")
                        continue
                        
                    # FarklÄ± yanÄ±t formatlarÄ± iÃ§in kontrol
                    if isinstance(js, dict):
                        # Data anahtarÄ±na sahip yanÄ±t formatÄ±
                        if "Rows" in js:
                            objects = js["Rows"]
                            if len(objects) > 0:
                                print(f"API baÅŸarÄ±lÄ± sonuÃ§ dÃ¶ndÃ¼: {len(objects)} nesne bulundu")
                                return pd.DataFrame(objects)
                            else:
                                print("API yanÄ±tÄ±nda Rows anahtarÄ± var ancak iÃ§i boÅŸ.")
                                continue
                        elif "data" in js:
                            objects = js["data"]
                            if len(objects) > 0:
                                print(f"API baÅŸarÄ±lÄ± sonuÃ§ dÃ¶ndÃ¼: {len(objects)} nesne bulundu")
                                return pd.DataFrame(objects)
                            else:
                                print("API yanÄ±tÄ±nda data anahtarÄ± var ancak iÃ§i boÅŸ.")
                                continue
                        elif "Column1" in js:
                            # BazÄ± eski SDSS API versiyonlarÄ± Column1, Column2... ÅŸeklinde dÃ¶ner
                            print("API Column1 formatÄ±nda yanÄ±t dÃ¶ndÃ¼")
                            return pd.DataFrame([js])
                        else:
                            # AnahtarlarÄ± doÄŸrudan sÃ¼tun olarak kullan
                            print("API farklÄ± bir formatta yanÄ±t dÃ¶ndÃ¼, doÄŸrudan anahtarlar kullanÄ±lÄ±yor")
                            return pd.DataFrame([js])
                    elif isinstance(js, list):
                        # DoÄŸrudan liste formatÄ±
                        if len(js) > 0:
                            print(f"API baÅŸarÄ±lÄ± liste yanÄ±tÄ± dÃ¶ndÃ¼: {len(js)} nesne")
                            return pd.DataFrame(js)
                        else:
                            print("API yanÄ±tÄ± boÅŸ liste iÃ§eriyor.")
                            continue
                    else:
                        print(f"API'dan beklenmeyen veri formatÄ± alÄ±ndÄ±: {type(js)}")
                        continue
                except ValueError as json_err:
                    # JSON parse hatasÄ± durumunda ham yanÄ±tÄ± incele ve devam et
                    resp_text = response.text[:1000]  # Ä°lk 1000 karakter
                    print(f"API yanÄ±tÄ± JSON olarak ayrÄ±ÅŸtÄ±rÄ±lamadÄ±: {json_err}. Ham yanÄ±t: {resp_text}...")
                    last_error = json_err
                    continue
            else:
                # HTTP hata kodunda bir sonraki API URL'yi dene
                print(f"API HTTP hata kodu: {response.status_code}")
                try:
                    error_content = response.text[:500]  # Ä°lk 500 karakter
                    print(f"Hata yanÄ±tÄ±: {error_content}")
                except:
                    print("Hata yanÄ±tÄ± okunamadÄ±")
                
                last_error = f"HTTP {response.status_code}"
                continue
                
        except Exception as e:            # Ä°stek hatasÄ±, bir sonraki URL'yi dene
            print(f"API istek hatasÄ±: {str(e)}")
            last_error = e
            continue
    
    # TÃ¼m URL'ler denendikten sonra hala baÅŸarÄ±sÄ±zsa, hata dÃ¶ndÃ¼r
    error_msg = f"TÃ¼m SDSS API URL'leri baÅŸarÄ±sÄ±z oldu. Son hata: {str(last_error) if last_error else 'Bilinmeyen hata'}"
    st.error(error_msg)
    print(error_msg)
    
    # KullanÄ±cÄ±ya arama yarÄ±Ã§apÄ±nÄ± artÄ±rmasÄ±nÄ± Ã¶ner
    if radius < 0.05:
        st.info(f"Ä°pucu: Arama yarÄ±Ã§apÄ±nÄ± artÄ±rmayÄ± deneyin (ÅŸu anki yarÄ±Ã§ap: {radius} derece). Daha bÃ¼yÃ¼k bir arama alanÄ±nda daha fazla gÃ¶k cismi bulunabilir.")
    
    return None

def pick_band(row, band):
    """
    SDSS Row / Series iÃ§inden istenen bandÄ±n magnitÃ¼dÃ¼nÃ¼ bulur.
    Tercih sÄ±rasÄ±:
      u, psfMag_u, modelMag_u, cModelMag_u, fiberMag_u, petroMag_u (+bÃ¼yÃ¼k harf)
    """
    prefixes = ["", "psfMag_", "modelMag_", "cModelMag_", "fiberMag_", "petroMag_"]
    cand_cols = [p + band for p in prefixes] + [band.upper()]
    for c in cand_cols:
        if c in row and pd.notna(row[c]):
            return float(row[c])
    return None



# UI baÅŸlÄ±ÄŸÄ± ve aÃ§Ä±klamasÄ±
st.title("ğŸŒŒ AI TabanlÄ± Astronomik GÃ¶k Cismi SÄ±nÄ±flandÄ±rÄ±cÄ±")
st.markdown("""
<div style="background-color:rgba(0, 0, 0, 0.7); padding: 10px; border-radius: 5px;">
    <p style="font-size: 18px; color: #ffffff;">
        Bu uygulama, Random Forest algoritmasÄ± kullanarak astronomik gÃ¶k cisimlerini sÄ±nÄ±flandÄ±rÄ±r. 
        SDSS verilerini kullanarak galaksi, kuasar ve yÄ±ldÄ±z tespiti yapabilirsiniz.
    </p>
</div>
""", unsafe_allow_html=True)

# ---------------------------------------------------------------------
# Ana UI yapÄ±sÄ±
# ---------------------------------------------------------------------
# Yan panel (sidebar) oluÅŸturma
st.sidebar.header("GÃ¶k Cismi AraÅŸtÄ±rma")
st.sidebar.markdown("SDSS veri tabanÄ±nÄ± kullanarak gÃ¶k cismi sÄ±nÄ±flandÄ±rmasÄ± yapÄ±n.")

# GiriÅŸ metodu seÃ§imi
input_method = st.sidebar.radio(
    "GiriÅŸ metodu seÃ§in:",
    ["GÃ¶kyÃ¼zÃ¼ HaritasÄ± ile Arama", "Manuel Filtreleme DeÄŸerleri", "CSV DosyasÄ± YÃ¼kleme"]
)

debug_mode = st.sidebar.checkbox("Debug modu")

def debug(*args, **kwargs):
    """Debug mod aÃ§Ä±ksa ekrana basar."""
    if debug_mode:
        st.write(*args, **kwargs)


# Modeli yÃ¼kle
with st.spinner("Random Forest modeli yÃ¼kleniyor..."):
    rf, scaler, labels = load_models()

if rf is not None and scaler is not None:
    st.sidebar.success("Random Forest modeli baÅŸarÄ±yla yÃ¼klendi! ğŸš€")
      # ---------------------------------------------------------
    # Koordinat ile arama
    # ---------------------------------------------------------
    if input_method == "GÃ¶kyÃ¼zÃ¼ HaritasÄ± ile Arama":
        
        st.subheader("GÃ¶kyÃ¼zÃ¼ HaritasÄ± ile GÃ¶k Cismi Ara")        
        st.markdown("##### SDSS DR18 Navigasyon AracÄ±")
        st.markdown("SDSS'in Aladin Sky Atlas kullanan navigasyon aracÄ±yla daha detaylÄ± inceleme yapabilirsiniz.")          
        sdss_iframe = """
        <iframe id="naviframe" scrolling="yes" allow="clipboard-write" 
                style="width: 100%; height: 750px; overflow: visible; border:1px solid #ccc; border-radius:5px; background-color: #fff;" 
                src="https://skyserver.sdss.org/navigate/?ra=180&dec=0&scale=0.3&dr=18&opt=&embedded=true"></iframe>
        """
        components.html(sdss_iframe, height=800)

        # ObjID ve Koordinat ile arama iÃ§in sekmeler oluÅŸtur
        tab1, tab2 = st.tabs(["ObjID ile Ara", "Koordinat ile Ara"])

        with tab1:
            st.markdown("### ObjID ile GÃ¶k Cismi Ara")
            objid_input = st.text_input("SDSS Nesne ID (objID)", placeholder="Ã–rnek: 1237668296598749280")

            if st.button("ObjID ile Ara ve SÄ±nÄ±flandÄ±r", key="objid_search"):
                if not objid_input.strip():
                    st.warning("LÃ¼tfen bir ObjID girin.")
                    st.stop()

                with st.spinner("SDSSâ€™ten veri Ã§ekiliyor..."):
                    try:
                        row = None
                        for dr in (18, 17, 16):
                            st.write(f"ObjID sorgulanÄ±yor, DR={dr}")
                            try:
                                # get_sdss_object_by_objid iÃ§inde kullanÄ±lan istek URL'sini de gÃ¶rmek iÃ§in debug
                                st.write("Sorgu yapÄ±lacak URL: <fonksiyondan_alÄ±nan_url>")  # Ã–rnek debug
                                data = get_sdss_object_by_objid(objid_input.strip(), dr=dr)
                                st.write(f"DR={dr} iÃ§in fonksiyon dÃ¶ndÃ¼rdÃ¼ÄŸÃ¼ veri: {data}")
                                if data is not None:
                                    row = data
                                    st.write(f"Veri bulundu: {row}")
                                    break
                                else:
                                    st.warning(f"Bu DR={dr} iÃ§in kayÄ±t bulunamadÄ±. ObjID, DR={dr} kapsamÄ± dÄ±ÅŸÄ±nda olabilir.")
                            except Exception as e:
                                st.error(f"DR{dr} sorgusu hata verdi: {e}")
                    except Exception as e:
                        st.error(f"SDSS servisine baÄŸlanÄ±lamadÄ±: {e}")
                        st.stop()

                if row is None:
                    st.error("Bu ObjID iÃ§in hiÃ§bir DR sÃ¼rÃ¼mÃ¼nde kayÄ±t bulunamadÄ±. ObjIDâ€™nin geÃ§erli olduÄŸundan emin olun veya farklÄ± bir Ã¶rnek deneyin.")
                    st.stop()

                # 2-c) Feature-vector oluÅŸtur
                u_  = pick_band(row, "u")
                g_  = pick_band(row, "g")
                r_  = pick_band(row, "r")
                i_  = pick_band(row, "i")
                z_  = pick_band(row, "z")

                missing = [b for b,v in zip("ugriz", (u_,g_,r_,i_,z_)) if v is None]
                if missing:
                    st.error(f"Bu nesnede fotometrik veri eksik ({', '.join(missing)} bandÄ± yok). "
                            "YarÄ±Ã§apÄ± bÃ¼yÃ¼tÃ¼p farklÄ± bir nesne deneyin.")
                    st.stop()

                fv = make_feature_vector(
                        u_, g_, r_, i_, z_,
                        plate   = row.get("plate",   0),
                        mjd     = row.get("mjd",     0),
                        fiberid = row.get("fiberid", 0),
                        redshift= row.get("redshift",0)
                )


                # Ã–lÃ§ekle + tahmin et
                X_scaled, _ = preprocess_data(fv, scaler)
                pred_class, confidence, class_probs = predict(X_scaled, rf, scaler, labels)

                # === SonuÃ§larÄ± gÃ¶ster ===
                st.success(f"Tahmin: **{pred_class}**  â€”  GÃ¼ven: **{confidence:.3f}**")
                st.markdown(get_object_info_text(pred_class, confidence))

                col1, col2 = st.columns(2)
                col1.pyplot(plot_predictions(pred_class, class_probs))
                col2.pyplot(display_confidence_gauge(confidence))

                # Ä°steÄŸe baÄŸlÄ±: gÃ¶kyÃ¼zÃ¼ gÃ¶rÃ¼ntÃ¼sÃ¼
                img = get_sdss_image(row["ra"], row["dec"], scale=0.3)
                if img:
                    st.image(img, caption="SDSS kesiti")
                else:
                    st.warning("LÃ¼tfen bir ObjID girin.")

        with tab2:
            st.markdown("### Koordinat ile GÃ¶k Cismi Ara")
            col1, col2 = st.columns(2)
            with col1:
                ra = st.number_input("SaÄŸ AÃ§Ä±klÄ±k (RA)", min_value=0.0, max_value=360.0, value=180.0, format="%.6f")
            with col2:
                dec = st.number_input("Dik AÃ§Ä±klÄ±k (Dec)", min_value=-90.0, max_value=90.0, value=0.0, format="%.6f")

            search_radius = st.slider("Arama YarÄ±Ã§apÄ± (derece)", 0.001, 0.05, 0.01, step=0.001, format="%.3f")

            if st.button("Koordinatlar ile Ara ve SÄ±nÄ±flandÄ±r", key="coord_search"):
                with st.spinner("SDSSâ€™ten veri Ã§ekiliyorâ€¦"):
                    # 2-a) Koordinata en yakÄ±n nesneyi Ã§ek
                    radius_arcsec = search_radius * 3600        # derece â†’ â€³
                    row = get_sdss_object_by_coords(ra, dec,
                                                    radius_arcsec=radius_arcsec)
                    if row is None:
                        st.error("SkyServer yanÄ±t vermedi veya bu koordinatta ugriz verisi yok. "
                                "â€¢ Ä°nternet/VPN engelini kontrol edin\n"
                                "â€¢ YarÄ±Ã§apÄ± bÃ¼yÃ¼tÃ¼p yeniden deneyin")
                        st.stop()

                if row is None:
                    st.error("Bu koordinatlarda nesne bulunamadÄ±; yarÄ±Ã§apÄ± bÃ¼yÃ¼tmeyi deneyin.")
                    st.stop()

                # 2-b) Astropy Row â†’ pandas.Series
                import pandas as pd

                if debug_mode:                # Sidebarâ€™daki "Debug modu" kutusu aÃ§Ä±kken
                    st.write("Gelen satÄ±r:", row)
                    if isinstance(row, pd.Series):
                        st.write("SÃ¼tun adlarÄ±:", row.index.tolist())
                    else:   # astropy Row
                        st.write("SÃ¼tun adlarÄ±:", row.colnames)

                 # 2-c) Feature-vector oluÅŸtur
                u_  = pick_band(row, "u")
                g_  = pick_band(row, "g")
                r_  = pick_band(row, "r")
                i_  = pick_band(row, "i")
                z_  = pick_band(row, "z")

                missing = [b for b,v in zip("ugriz", (u_,g_,r_,i_,z_)) if v is None]
                if missing:
                    st.error(f"Fotometrik veri eksik: {', '.join(missing)} band(lar)Ä± yok.\n"
                            "â€¢ AynÄ± koordinatta farklÄ± objeler olabilir.\n"
                            "â€¢ YarÄ±Ã§apÄ± bÃ¼yÃ¼tÃ¼p baÅŸka bir nesne seÃ§in **ya da** u/g/r/i/z "
                            "alanÄ± iÃ§eren PhotoObj kaydÄ±nÄ± SQL ile Ã§aÄŸÄ±rÄ±n.")
                    st.stop()

                fv = make_feature_vector(
                        u_, g_, r_, i_, z_,
                        plate   = row.get("plate",   0),
                        mjd     = row.get("mjd",     0),
                        fiberid = row.get("fiberid", 0),
                        redshift= row.get("redshift",0)
                )


                # 2-d) Ã–lÃ§ekle + tahmin et
                X_scaled, _ = preprocess_data(fv, scaler)
                pred_class, confidence, class_probs = predict(X_scaled, rf, scaler, labels)

                # 2-e) SonuÃ§larÄ± gÃ¶ster
                st.success(f"Tahmin: **{pred_class}**  â€”  GÃ¼ven: **{confidence:.3f}**")
                st.markdown(get_object_info_text(pred_class, confidence))

                col1, col2 = st.columns(2)
                col1.pyplot(plot_predictions(pred_class, class_probs))
                col2.pyplot(display_confidence_gauge(confidence))

                # 2-f) SDSS gÃ¶rÃ¼ntÃ¼sÃ¼
                img = get_sdss_image(row["ra"], row["dec"], scale=0.3)
                if img:
                    st.image(img, caption="SDSS kesiti")

                
    # ---------------------------------------------------------
    # Manuel Filtreleme DeÄŸerleri
    # ---------------------------------------------------------
    elif input_method == "Manuel Filtreleme DeÄŸerleri":
        st.subheader("Fotometrik DeÄŸerlerle Manuel SÄ±nÄ±flandÄ±rma")        
        st.markdown("""
        SDSS'in beÅŸ temel fotometrik filtreleme deÄŸerlerini (u, g, r, i, z) girerek sÄ±nÄ±flandÄ±rma yapabilirsiniz.
        DeÄŸerleri kadir (magnitude) cinsinden giriniz.
        """)        
        col1, col2, col3, col4, col5 = st.columns(5)
        with col1:
            u_mag = st.number_input("u filtresi (kadir)", min_value=10.0, max_value=30.0, value=19.0, format="%.5f")
        with col2:
            g_mag = st.number_input("g filtresi (kadir)", min_value=10.0, max_value=30.0, value=17.5, format="%.5f")
        with col3:
            r_mag = st.number_input("r filtresi (kadir)", min_value=10.0, max_value=30.0, value=16.8, format="%.5f")
        with col4:
            i_mag = st.number_input("i filtresi (kadir)", min_value=10.0, max_value=30.0, value=16.5, format="%.5f")
        with col5:
            z_mag = st.number_input("z filtresi (kadir)", min_value=10.0, max_value=30.0, value=16.2, format="%.5f")
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            plate = st.number_input("Plate ID", min_value=0, max_value=20000, value=1000)
        with col2:
            mjd = st.number_input("MJD (Modified Julian Date)", min_value=50000, max_value=60000, value=55000)
        with col3:
            fiberid = st.number_input("Fiber ID", min_value=0, max_value=1000, value=500)
        with col4:
            redshift = st.number_input("Redshift (z)", min_value=-1.0, max_value=10.0, value=0.1, format="%.10f")
        
        if st.button("SÄ±nÄ±flandÄ±r", key="manual_classify"):
            try:
                # Ã–zellik vektÃ¶rÃ¼ oluÅŸtur
                sample_df = make_feature_vector(
                    u_mag, g_mag, r_mag, i_mag, z_mag,
                    plate=plate, mjd=mjd, fiberid=fiberid, redshift=redshift
                )

                # Debug bilgisi
                st.write(f"Debug - OluÅŸturulan DataFrame: ÅŸekil={sample_df.shape}, tip={type(sample_df)}")

                # Tahmini yap
                with st.spinner("SÄ±nÄ±flandÄ±rma yapÄ±lÄ±yor..."):
                    # preprocess_data ile CSV bÃ¶lÃ¼mÃ¼nde kullanÄ±lan aynÄ± yÃ¶ntemi kullan
                    X_scaled, _ = preprocess_data(sample_df, scaler, debug=True)
                    
                    if X_scaled is None:
                        st.error("Veri Ã¶n iÅŸleme baÅŸarÄ±sÄ±z oldu.")
                    else:
                        # Model ile tahmin
                        rf_probs = rf.predict_proba(X_scaled)
                        pred_classes_idx = rf_probs.argmax(1)
                        pred_class = labels[pred_classes_idx[0]]
                        confidence = rf_probs[0, pred_classes_idx[0]]
                        
                        # TÃ¼m sÄ±nÄ±f olasÄ±lÄ±klarÄ±nÄ± hazÄ±rla
                        class_probs = {label: float(rf_probs[0, i]) for i, label in enumerate(labels)}
                      # SonuÃ§larÄ± gÃ¶ster
                    st.subheader(f"SÄ±nÄ±flandÄ±rma Sonucu: {pred_class}")
                    st.markdown(f"**GÃ¼ven DeÄŸeri:** {confidence:.4f}")
                    
                    # Tahmin olasÄ±lÄ±klarÄ±nÄ± gÃ¶ster
                    st.write("Tahmin olasÄ±lÄ±klarÄ±:")
                    for cls, prob in class_probs.items():
                        st.write(f"{cls}: {prob:.4f}")
                    
                    # AÃ§Ä±klama ekle
                    st.markdown(get_object_info_text(pred_class, confidence))
                    
                    # Renk indekslerini gÃ¶ster
                    st.subheader("Renk Ä°ndeksleri")
                    col1, col2, col3, col4 = st.columns(4)
                    col1.metric("u - g", f"{(u_mag - g_mag):.2f}")
                    col2.metric("g - r", f"{(g_mag - r_mag):.2f}")
                    col3.metric("r - i", f"{(r_mag - i_mag):.2f}")
                    col4.metric("i - z", f"{(i_mag - z_mag):.2f}")
                    
                    # Grafik gÃ¶ster
                    col1, col2 = st.columns(2)
                    with col1:
                        st.pyplot(plot_predictions(pred_class, class_probs))
                    with col2:
                        st.pyplot(display_confidence_gauge(confidence))
                    
            except Exception as e:
                st.error(f"SÄ±nÄ±flandÄ±rma hatasÄ±: {str(e)}")
    # ---------------------------------------------------------
    # CSV DosyasÄ± YÃ¼kleme
    # ---------------------------------------------------------
    elif input_method == "CSV DosyasÄ± YÃ¼kleme":
        st.subheader("CSV DosyasÄ± ile Toplu SÄ±nÄ±flandÄ±rma")
        st.markdown("""
        CSV dosyasÄ± yÃ¼kleyerek birden fazla gÃ¶k cismini toplu olarak sÄ±nÄ±flandÄ±rabilirsiniz.
        
        CSV dosyanÄ±zda en azÄ±ndan `u`, `g`, `r`, `i`, `z` sÃ¼tunlarÄ± bulunmalÄ±dÄ±r. Opsiyonel olarak `class` sÃ¼tunu 
        eklerseniz, tahminlerin doÄŸruluÄŸunu deÄŸerlendirebilirsiniz.
        """)
        
        uploaded_file = st.file_uploader("CSV dosyasÄ± yÃ¼kleyin", type=['csv'])
        
        if uploaded_file is not None:
            try:
                df = pd.read_csv(uploaded_file)                
                st.write("CSV dosyasÄ± yÃ¼klendi! Ä°lk birkaÃ§ satÄ±r:")
                st.dataframe(df.head())
                
                # Gerekli sÃ¼tunlarÄ±n olup olmadÄ±ÄŸÄ±nÄ± kontrol et
                required_cols = ['u', 'g', 'r', 'i', 'z']
                if all(col in df.columns for col in required_cols):
                    show_debug = st.checkbox("Hata ayÄ±klama bilgilerini gÃ¶ster", value=False)
                    if st.button("Toplu SÄ±nÄ±flandÄ±r", key="batch_classify"):                        
                        with st.spinner("SÄ±nÄ±flandÄ±rma yapÄ±lÄ±yor... Bu biraz zaman alabilir."):
                            try:
                                # test_rf.py'de kullanÄ±lan preprocess_data fonksiyonunu kullan
                                X_scaled, true_classes = preprocess_data(df, scaler, debug=show_debug)
                                
                                if X_scaled is None:
                                    st.error("Veri Ã¶n iÅŸleme baÅŸarÄ±sÄ±z oldu.")
                                else:
                                    # Tahmin yap
                                    start_time = time.time()
                                    rf_probs = rf.predict_proba(X_scaled)
                                    
                                    # SonuÃ§larÄ± Ã§Ä±kar
                                    pred_classes_idx = rf_probs.argmax(1)
                                    pred_classes = [labels[idx] for idx in pred_classes_idx]
                                    confidences = [rf_probs[i, idx] for i, idx in enumerate(pred_classes_idx)]
                                    
                                    # SonuÃ§larÄ± DataFrame'e ekle
                                    results_df = df.copy()
                                    results_df['predicted_class'] = pred_classes
                                    results_df['confidence'] = confidences
                                    
                                    # SonuÃ§larÄ± gÃ¶ster
                                    st.success(f"SÄ±nÄ±flandÄ±rma tamamlandÄ±! ({time.time() - start_time:.2f} saniye)")
                                    st.dataframe(results_df)
                                    
                                    # Ä°statistikler
                                    st.subheader("SÄ±nÄ±flandÄ±rma Ä°statistikleri")
                                    
                                    # SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±
                                    class_dist = pd.Series(pred_classes).value_counts()
                                    st.bar_chart(class_dist)
                                    
                                    col1, col2 = st.columns(2)
                                    with col1:
                                        st.metric("Ortalama GÃ¼ven", f"{np.mean(confidences):.4f}")
                                    with col2:
                                        st.metric("Medyan GÃ¼ven", f"{np.median(confidences):.4f}")
                                    
                                    # GerÃ§ek deÄŸerler ile karÅŸÄ±laÅŸtÄ±rma
                                    has_class = 'class' in df.columns and true_classes is not None
                                    if has_class:
                                        from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
                                        
                                        accuracy = accuracy_score(true_classes, pred_classes)
                                        st.metric("DoÄŸruluk (Accuracy)", f"{accuracy:.4f}")
                                        
                                        st.subheader("SÄ±nÄ±flandÄ±rma Raporu")
                                        report = classification_report(true_classes, pred_classes, output_dict=True)
                                        report_df = pd.DataFrame(report).transpose()
                                        st.dataframe(report_df)
                                        
                                        st.subheader("KarmaÅŸÄ±klÄ±k Matrisi")
                                        cm = confusion_matrix(true_classes, pred_classes)
                                        fig, ax = plt.subplots(figsize=(8, 6))
                                        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                                                    xticklabels=labels,
                                                    yticklabels=labels)
                                        plt.title('KarmaÅŸÄ±klÄ±k Matrisi')
                                        plt.xlabel('Tahmin Edilen SÄ±nÄ±f')
                                        plt.ylabel('GerÃ§ek SÄ±nÄ±f')
                                        st.pyplot(fig)
                                    
                                    # SonuÃ§larÄ± CSV olarak indirme
                                    csv = results_df.to_csv(index=False)
                                    b64 = base64.b64encode(csv.encode()).decode()
                                    href = f'<a href="data:file/csv;base64,{b64}" download="siniflandirma_sonuclari.csv">SonuÃ§larÄ± CSV Olarak Ä°ndir</a>'
                                    st.markdown(href, unsafe_allow_html=True)
                            except Exception as e:
                                st.error(f"SÄ±nÄ±flandÄ±rma sÄ±rasÄ±nda hata oluÅŸtu: {str(e)}")
                else:
                    missing = [col for col in required_cols if col not in df.columns]
                    st.error(f"CSV dosyasÄ±nda gerekli sÃ¼tunlar eksik: {', '.join(missing)}")            
            except Exception as e:
                st.error(f"CSV dosyasÄ± iÅŸlenirken hata oluÅŸtu: {str(e)}")
else:
    st.error("Random Forest modeli yÃ¼klenemedi. LÃ¼tfen model dosyalarÄ±nÄ± kontrol edin.")

# ---------------------------------------------------------------------
# HakkÄ±nda bÃ¶lÃ¼mÃ¼
# ---------------------------------------------------------------------
st.sidebar.markdown("---")
st.sidebar.header("HakkÄ±nda")
st.sidebar.markdown("""
Bu uygulama, bir Random Forest modeli kullanarak SDSS fotometrik verilerinden
gÃ¶ksel cisimleri (Galaksi, QSO/Kuasar, YÄ±ldÄ±z) sÄ±nÄ±flandÄ±rÄ±r.

Model, SDSS DR18 veri setindeki 100.000+ Ã¶rnek ile eÄŸitilmiÅŸtir.
""")
